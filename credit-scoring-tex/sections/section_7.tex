\section{Conclusão}

Neste trabalho, buscamos comparar alguns classificadores na tarefa de análise de crédito, de maneira a criar um modelo que apresentasse os melhores resultados da métrica KS para o problema estabelecido. Observamos que os \textit{ensembles} baseados em árvore e com \textit{Gradient Boosting} atingiram os melhores resultados, respectivamente \textit{XGBoost} e \textit{LightGBM}. Também observamos que o \textit{XGBoost} obteve um melhor KS em teste (27.1), apesar de ambos modelos não apresentarem diferença estatística significativa.

Para esse trabalho, foi de fundamental importância o processo de seleção de atributos, de maneira que apenas os filtros não foram suficientes para atingirmos os resultados apresentados. A combinação de atributos importantes para os modelos, bem como atributos importantes para os métodos de filtro, resultaram em melhores valores de KS, uma vez que a combinação de \textit{features} tem o potencial de alavancar melhores resultados, principalmente se realizadas combinações onde os atributos geram bastante informação para a aprendizagem dos modelos.

Em trabalhos futuros, é interessante explorar o processo de \textit{feature engineering}, criando atributos que aumentem os valores de KS para os modelos. Também poderíamos criar uma rede neural para esse problema, passando novas \textit{features} e normalizando os dados; por fim, poderíamos combinar um dos modelos baseados em árvore (\textit{XGBoost} ou \textit{LightGBM}) com a rede criada através de um meta classificador (uma ideia é o \textit{StackingClassifier} do módulo \textit{sklearn}), gerando resultados mais robustos.